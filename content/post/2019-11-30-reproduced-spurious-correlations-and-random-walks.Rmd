---
title: '[Reproduced] Spurious Correlations and Random Walks'
author: yjtek
date: '2019-11-30'
slug: spurious-correlations-and-random-walks
categories: []
tags: []
draft: true
---

<style type="text/css">
<!-- body, td { -->
<!--    font-size: 14px; -->
<!-- } -->
<!-- code.r{ -->
<!--   font-size: px; -->
<!-- } -->
pre {
  font-size: 15px
}
p.caption {
  font-size: 13px;
  color: grey;
  font-style: italic;
  text-align: center;
}
</style>

```{r, echo = F, include = F}
library(tidyverse)
library(gridExtra)
```

*Reproduced from [Fabian Dablander](https://fabiandablander.com/r/Spurious-Correlation.html)*
<br>
<br>

### Introduction

This piece will explore the implications of random walk processes in inducing spurious correlations and false positives in hypothesis testing. 

Recall that an AR series generally takes the following form:  
<br>
<center> $Y_{t} = \phi Y_{t-1} + \epsilon_{t}$ --- (1) </center>
<br>
where $\phi$ measures the autocorrelation, and $\epsilon \sim \mathbb{N}(0,\sigma^{2})$. Note that a random walk is just a special case of the AR process where $\phi$ = 1.
<br>
<br>

### Randomness in random walks

To explore the impact of $\phi$ in generating data, we build a function that simulates a data generating process given values of 

```{r}
simulate_ar <- function(n, phi, sigma = .1) {
  y <- rep(0, n)
  for (t in seq(2, n)) {
    y[t] <- phi*y[t-1] + rnorm(1, 0, sigma)
  }
  y
}
```

where $n$ determines the number of datapoints to generate; $\phi$ is the first order autocorrelation, and $\sigma$ is the variance of the errors in $\epsilon$.

As an example, let's generate 3 AR(1) processes and 3 random walks and chart them. Notice how much better behaved the AR processes are compared to the random walk.

```{r}
n <- 100
set.seed(1)
 
rw1 <- simulate_ar(n, phi = 1)
rw2 <- simulate_ar(n, phi = 1)
rw3 <- simulate_ar(n, phi = 1)

ar1 <- simulate_ar(n, phi = 0.5)
ar2 <- simulate_ar(n, phi = 0.5)
ar3 <- simulate_ar(n, phi = 0.5)
```

Looking at Figure \@ref(fig:combined), it's clear that the random walk processes are much more erratic than the AR processes ($\phi$ = 0.5), also called "non-stationary" in statistical gobbledygook.

```{r combined, fig.cap='AR vs Random Walk', tidy = F, echo = F}
combinedPlot <- data.frame(
  Time = rep(seq.int(1,100), 3), 
  Values = c(ar1, ar2, ar3, rw1, rw2, rw3),
  Group = rep(c('AR_1', 'AR_2', 'AR_3', 'RW_1', 'RW_2', 'RW_3'), each = 100)
  ) %>% 
  mutate(Group = factor(Group))

combinedPlot %>%
  ggplot(aes(x = Time, y = Values,  colour = `Group`)) + 
  geom_line() +
  geom_point() + 
  theme_classic() + 
  scale_colour_manual(values = c('#6C6B74', '#2E303E', '#212624', '#F22F08', '#FAAB00', '#2721DB'))
``` 

### Why care about this?

For one, correlations computed with random walks are unreliable (jargon: spurious). This is clear from the correlation tables below - the correlation between random walk series clearly exceed those seen in the AR1.

```{r, echo = F, results=F}
library(kableExtra)
```


```{r, echo = F, fig.cap = 'Correlation between random walks'}
t1 <- round(cor(cbind(red = rw1, green = rw2, blue = rw3)), 2)
t2 <- round(cor(cbind(red = ar1, green = ar2, blue = ar3)), 2)
knitr::kable(list(t1, t2), caption = 'test') %>%
  kable_styling(bootstrap_options = "striped", full_width = F, position = "center")
```

With that said,




