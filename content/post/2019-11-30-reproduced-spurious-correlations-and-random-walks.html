---
title: '[Reproduced] Spurious Correlations and Random Walks'
author: yjtek
date: '2019-11-30'
slug: spurious-correlations-and-random-walks
categories: []
tags: []
draft: true
---



<style type="text/css">
<!-- body, td { -->
<!--    font-size: 14px; -->
<!-- } -->
<!-- code.r{ -->
<!--   font-size: px; -->
<!-- } -->
pre {
  font-size: 15px
}
</style>
<p><em>Reproduced from <a href="https://fabiandablander.com/r/Spurious-Correlation.html">Fabian Dablander</a></em>
<br>
<br></p>
<div id="introduction" class="section level3">
<h3>Introduction</h3>
<p>This piece will explore the implications of random walk processes in inducing spurious correlations and false positives in hypothesis testing.</p>
Recall that an AR series generally takes the following form:<br />
<br>
<center>
<span class="math inline">\(Y_{t} = \phi Y_{t-1} + \epsilon_{t}\)</span> — (1)
</center>
<p><br>
where <span class="math inline">\(\phi\)</span> measures the autocorrelation, and <span class="math inline">\(\epsilon \sim \mathbb{N}(0,\sigma^{2})\)</span>. Note that a random walk is just a special case of the AR process where <span class="math inline">\(\phi\)</span> = 1.
<br>
<br></p>
</div>
<div id="simulation" class="section level3">
<h3>Simulation</h3>
<p>To explore the impact of <span class="math inline">\(\phi\)</span> in generating data, we build a function that simulates a data generating process given values of</p>
<pre class="r"><code>simulate_ar &lt;- function(n, phi, sigma = .1) {
  y &lt;- rep(0, n)
  for (t in seq(2, n)) {
    y[t] &lt;- phi*y[t-1] + rnorm(1, 0, sigma)
  }
  y
}</code></pre>
<p>where <span class="math inline">\(n\)</span> determines the number of datapoints to generate; <span class="math inline">\(\phi\)</span> is the first order autocorrelation, and <span class="math inline">\(\sigma\)</span> is the variance of the errors in <span class="math inline">\(\epsilon\)</span>.</p>
<p>As an example, let’s generate 3 AR(1) processes and 3 random walks and chart them. Notice how much better behaved the AR processes are compared to the random walk.</p>
<pre class="r"><code>n &lt;- 100
set.seed(1)
 
rw1 &lt;- simulate_ar(n, phi = 1)
rw2 &lt;- simulate_ar(n, phi = 1)
rw3 &lt;- simulate_ar(n, phi = 1)

ar1 &lt;- simulate_ar(n, phi = 0.5)
ar2 &lt;- simulate_ar(n, phi = 0.5)
ar3 &lt;- simulate_ar(n, phi = 0.5)</code></pre>
<p>Looking at Figure <a href="#fig:combined">1</a>, it’s clear that the random walk processes are much more erratic than the AR processes (<span class="math inline">\(\phi\)</span> = 0.5). This phenomonon is also called “non-stationarity” in statistical gobbledygook.</p>
<div class="figure"><span id="fig:combined"></span>
<img src="/post/2019-11-30-reproduced-spurious-correlations-and-random-walks_files/figure-html/combined-1.png" alt="AR vs Random Walk" width="672" />
<p class="caption">
Figure 1: AR vs Random Walk
</p>
</div>
</div>
