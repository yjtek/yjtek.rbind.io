<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.59.1" />


<title>Markov Chain Monte Carlo (MCMC) - Gibbs Sampling - Sandbox</title>
<meta property="og:title" content="Markov Chain Monte Carlo (MCMC) - Gibbs Sampling - Sandbox">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/yjtek">GitHub</a></li>
    
    <li><a href="https://twitter.com/yjtek">Twitter</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">6 min read</span>
    

    <h1 class="article-title">Markov Chain Monte Carlo (MCMC) - Gibbs Sampling</h1>

    
    <span class="article-date">2020-03-03</span>
    

    <div class="article-content">
      


<pre><code>## ── Attaching packages ───────────────────────────── tidyverse 1.3.0 ──</code></pre>
<pre><code>## ✓ ggplot2 3.2.1     ✓ purrr   0.3.3
## ✓ tibble  2.1.3     ✓ dplyr   0.8.4
## ✓ tidyr   1.0.2     ✓ stringr 1.4.0
## ✓ readr   1.3.1     ✓ forcats 0.4.0</code></pre>
<pre><code>## ── Conflicts ──────────────────────────────── tidyverse_conflicts() ──
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<p><em>Based on “A simple introduction to Markov Chain Monte–Carlo sampling” by <a href="https://link.springer.com/content/pdf/10.3758%2Fs13423-016-1015-8.pdf">Ravenzwaaij et al.</a>:</em></p>
<p>In an <a href="/2020/03/01/markov-chain-monte-carlo-mcmc-metropolis-hastings/">earlier post</a>, I discussed the basic idea of MCMC methods, and provided an overview of the Metropolis algorithm. In this section, I’ll jump straight into the motivation for Gibbs Sampling, and an overview of how the algorithm works.</p>
<div id="what-is-the-point-of-gibbs-sampling-if-we-already-know-the-metropolis-algorithm" class="section level3">
<h3>What is the point of Gibbs Sampling if we already know the Metropolis algorithm?</h3>
<p>Both Gibbs Sampling and the Metropolis Algorithm are actually pretty similar in terms of the general structure. Both use an accept-reject algorithm to iteratively draw samples from the underlying unknown distribution to move towards the most likely distribution. The key difference is in the proposal step for the new values in every iteration - while the Metropolis algorithm samples from the <em>joint</em> probability distribution of the parameters, Gibbs Sampling draws from the <em>conditional</em> distribution instead.</p>
<p>Mathematically, this means that the Metropolis algorithm compares <span class="math inline">\(\frac{L^{met}_1}{L^{met}_{0}} = \frac{\prod_{i = 1}^{n}{P(\mathbf{x_i}|\mu_1, \sigma_1)}}{\prod_{i = 1}^{n}{P(\mathbf{x_i}|\mu_0, \sigma_0)}}\)</span>; that is, what is the likelihood of the data under the current set of parameters <span class="math inline">\((\mu_0, \sigma_0)\)</span> compared to the likelihood of the data under a new set of parameters <span class="math inline">\((\mu_1, \sigma_1)\)</span>. Notice that my new parameters are varied at the same time, i.e. they are sampled jointly from the unknown distribution of <span class="math inline">\((\mu, \sigma)\)</span>.</p>
<p>While the Metropolis algorithm works well in most cases, there are situations where it can converge too slowly to provide a meaningful answer. For instance, if the underlying parameters are highly correlated, the Metropolis algorithm will reject an overly large number of samples, leading to slow convergence.</p>
<p><img src="/post/2020-03-03-markov-chain-monte-carlo-mcmc-gibbs-sampling_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p>This is best illustrated by an example. The chart above shows a scatter plot of 2 parameters. Suppose we start off at the orange point as our prior value. The Metropolis algorithm effectively samples the space around the chosen point uniformly to arrive at the next proposal. As you might imagine, this leads to more rejections than necessary since a large proportion of the proposals will not take the parameter correlation into account.</p>
</div>
<div id="gibbs-sampling" class="section level3">
<h3>Gibbs Sampling</h3>
<p>The main insight of Gibbs sampling is: wherever drawing from the joint distribution is suboptimal (for whatever reason), why not try drawing from the <em>condition</em> distribution instead? In this way, the joint distribution between parameters is respected over an extended number of iterations. <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>The Gibbs Sampling Algorithm is summarised below: <br></p>
<ol style="list-style-type: decimal">
<li>Give your best guess for the parameter(s) of interest. In this case, let’s say this is <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. We will call this <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\sigma_0\)</span></li>
<li>Next, we compute the likelihood <span class="math inline">\(L_0\)</span> of the parameter being <span class="math inline">\(\mu_0\)</span> conditional on the data we observe, or <span class="math inline">\(P(\mu_0 | Data)\)</span>. By Bayes’ rule, this is equal to <span class="math inline">\(\frac{P(Data | \mu_0, \sigma_0) \cdotp P(\mu_0, \sigma_0)}{P(Data)}\)</span>.</li>
<li>Add a random perturbation to <strong>one</strong> of your parameters, holding everything else constant. Suppose we add a random perturbation to <span class="math inline">\(\mu_0\)</span>. Let’s call this new parameter <span class="math inline">\(\mu_1\)</span>.</li>
<li>Again, compute the likelihood <span class="math inline">\(L_1\)</span> of the parameters being <span class="math inline">\((\mu_1, \sigma_0)\)</span> conditional on the data you observe, <span class="math inline">\(P(\mu_1, \sigma_0 | Data)\)</span></li>
<li>Compare the likelihood scores of hyperparameters given the data.
<ol style="list-style-type: lower-alpha">
<li>If <span class="math inline">\(L_1\)</span> &gt; <span class="math inline">\(L_0\)</span>, <span class="math inline">\((\mu_1, \sigma_0)\)</span> becomes your best guess</li>
<li>If <span class="math inline">\(L_1\)</span> &lt;= <span class="math inline">\(L_0\)</span>, <span class="math inline">\((\mu_1, \sigma_0)\)</span> is chosen with probability <span class="math inline">\(L_1 / L_2\)</span></li>
</ol></li>
<li>For illustration, let’s assume the proposed <span class="math inline">\(\mu_1\)</span> was accepted. We now hold <span class="math inline">\(\mu_1\)</span> constant, and add a random perturbation to <span class="math inline">\(\sigma_0\)</span>. Let’s now call this <span class="math inline">\(\sigma_1\)</span>.</li>
<li>Compute the likelihood <span class="math inline">\(L_2\)</span> of the parameters being <span class="math inline">\((\mu_1, \sigma_1)\)</span> conditional on the data you observe, <span class="math inline">\(P(\mu_1, \sigma_1 | Data)\)</span></li>
<li>Compare the likelihood scores of hyperparameters given the data.
<ol style="list-style-type: lower-alpha">
<li>If <span class="math inline">\(L_2\)</span> &gt; <span class="math inline">\(L_1\)</span>, <span class="math inline">\((\mu_1, \sigma_1)\)</span> becomes your best guess</li>
<li>If <span class="math inline">\(L_2\)</span> &lt;= <span class="math inline">\(L_1\)</span>, <span class="math inline">\((\mu_1, \sigma_1)\)</span> is chosen with probability <span class="math inline">\(L_2 / L_1\)</span></li>
</ol></li>
<li>Repeat from step 1 for a given number of iterations</li>
</ol>
<pre class="r"><code>gibbs_sampling &lt;- function(data, proposed_mu, proposed_sigma, niter = 500){
  
  proposed_param = data.frame(proposed_mu = proposed_mu, proposed_sigma = proposed_sigma)
  accept_param = data.frame(accept_mu = proposed_mu, accept_sigma = proposed_sigma)
  
  current_mu = proposed_mu
  current_sigma = proposed_sigma
  
  for(i in 1:niter){
    
    # Proposal for mu ====
    proposal_draw = rnorm(1, 0, 5)
    
    # Compare the earlier proposal value for mu with the new. 
    candidate1 = sum(log(dnorm(data, current_mu, current_sigma)))
    candidate2 = sum(log(dnorm(data, current_mu + proposal_draw, current_sigma)))
    proposed_param = proposed_param %&gt;%
      bind_rows(data.frame(proposed_mu = current_mu + proposal_draw, proposed_sigma = current_sigma))
    
    # If new proposed value gives you a higher chance of observing first_value, accept it. Otherwise, accept new proposal with probability proportionate to how much lower the posterior is compared to the original proposal. This prevents getting stuck in local maxima.
    if(candidate2 &gt; candidate1){
      current_mu = current_mu + proposal_draw
    } else {
      if(runif(1, 0, 1) &lt;= (exp(candidate2 - candidate1))){
        current_mu = current_mu + proposal_draw
      }
    }
    accept_param = accept_param %&gt;%
      bind_rows(data.frame(accept_mu = current_mu, accept_sigma = current_sigma))
    
    # Proposal for sigma ====
    
    proposal_draw = rnorm(1, 0, 2)
    
    # Compare the earlier proposal value for mu with the new. 
    candidate1 = sum(log(dnorm(data, current_mu, current_sigma)))
    candidate2 = sum(log(dnorm(data, current_mu, current_sigma + proposal_draw)))
    proposed_param = proposed_param %&gt;%
      bind_rows(data.frame(proposed_mu = current_mu, proposed_sigma = current_sigma + proposal_draw))
    # If new proposed value gives you a higher chance of observing first_value, accept it. Otherwise, accept new proposal with probability proportionate to how much lower the posterior is compared to the original proposal. This prevents getting stuck in local maxima.
    if(candidate2 &gt; candidate1){
      current_sigma = current_sigma + proposal_draw
    } else {
      if(runif(1, 0, 1) &lt;= (exp(candidate2 - candidate1))){
        current_sigma = current_sigma + proposal_draw
      }
    }
    accept_param = accept_param %&gt;%
      bind_rows(data.frame(accept_mu = current_mu, accept_sigma = current_sigma))
    
  }
  return(proposed_param %&gt;% bind_cols(accept_param))
}</code></pre>
<p>Looking at the path of the parameters taken by the Gibbs sampler, we can see the distinct unidirectional pattern at each stage of the accept-reject algorithm.</p>
<pre class="r"><code>gibbs_sampling(student_results, proposed_mu = 10, proposed_sigma = 100, niter = 1000) %&gt;%
  mutate(series = 1:2001) %&gt;%
  ggplot(aes(x = accept_sigma, y = accept_mu, colour = series)) +
  geom_point() +
  geom_path() +
  theme_classic() +
  theme(legend.position = &#39;none&#39;)</code></pre>
<p><img src="/post/2020-03-03-markov-chain-monte-carlo-mcmc-gibbs-sampling_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Comparing this to the Metropolis algorithm:</p>
<pre class="r"><code>metropolis_algo_multiDim(student_results, proposed_mu = 10, proposed_sigma = 100, niter = 1000) %&gt;%
  mutate(series = 1:1001) %&gt;%
  ggplot(aes(x = accepted_sigma, y = accepted_mu, colour = series)) +
  geom_point() +
  geom_path() +
  theme_classic() +
  theme(legend.position = &#39;none&#39;)</code></pre>
<p><img src="/post/2020-03-03-markov-chain-monte-carlo-mcmc-gibbs-sampling_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>It’s clear how the two sampling algorithms differ in their accept-reject procedures.</p>
</div>
<div id="conclusion" class="section level3">
<h3>Conclusion</h3>
<p>In this post, we covered the motivation for more complex sampling methodologies like Gibbs sampling in dealing with cases where the sampled parameters are correlated. In the next post, I will discuss another methodology used in these sampling methods - differential evolution.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>See this set of <a href="http://www2.stat.duke.edu/~rcs46/modern_bayes17/lecturesModernBayes17/lecture-7/07-gibbs.pdf">notes</a> on Gibbs sampling for more details<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

